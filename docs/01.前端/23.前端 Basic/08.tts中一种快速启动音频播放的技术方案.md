---
title: tts中一种快速启动音频播放的技术方案
date: 2024-04-10 10:59:49
permalink: /pages/7da042/
categories:
  - 前端
  - 前端 Basic
tags:
  - 
author: 
  name: suxuewb
  link: https://github.com/suxuelengyin
---
文本转语音（tts）是常见的需求，一般是提前生成好音频文件，然后在需要的时候播放。但是有时候我们需要实时播放音频，比如语音助手、语音聊天等场景。这时候就需要一种快速启动音频播放的技术方案。本文介绍一种基于 `MediaSource` 的技术方案，可以实现快速启动音频播放。

## 1. MediaSource 简介

[Media Source Extensions](https://developer.mozilla.org/zh-CN/docs/Web/API/MediaSource)（媒体源扩展）大大地扩展了浏览器的媒体播放功能，提供允许JavaScript 生成媒体流。
MediaSource 对象可以附着在 HTMLMediaElement 在客户端进行播放。基本原理就是类似于直播流，通过 MediaSource 对象生成一个媒体流，将媒体流附着在html媒体元素上进行播放。

使用前需要检查浏览器是否支持 MediaSource：
```javascript
if (!('MediaSource' in window)){
    throw new Error('不支持MediaSource')
}
```

> 微信内置浏览器可能不支持 MediaSource。


## 2. 创建播放流程

创建 MediaSource:
```javascript
const mediaSource = new MediaSource();
```
创建AudioElement:
```javascript
const audioElement = new Audio();
```
将 MediaSource 附着到 AudioElement 上：
```javascript
audioElement.src = URL.createObjectURL(mediaSource);
```
此时的播放流程为`MediaSource -> AudioElement -> 播放`

如果你想做音频可视化，可以将AudioElement的播放交给AudioContext接管：
```javascript
// 创建AudioContext
const audioContext = new AudioContext();
// 接管audioElement的播放
const source = audioContext.createMediaElementSource(audioElement);
// 使用音量节点，可以做音量可视化
const gainNode = audioContext.createGain();
// 连接音量节点
source.connect(gainNode);
// 使用分析器节点，可以做频谱可视化
const analyserNode = audioContext.createAnalyser();
// 连接分析器节点
gainNode.connect(analyserNode);
//播放交给AudioContext接管后，最终必须连接到扬声器节点destination，否则无法播放
analyserNode.connect(audioContext.destination);
```
此时的播放流程为`MediaSource -> AudioElement -> AudioContext- > gainNode -> analyserNode -> destination播放`

**如果想查看播放流程，可以使用chrome插件`Audion`查看。**

最终使用`audioElement.play()`来播放。

> AudioElement的播放交给AudioContext接管后，进行播放/暂停等操作仍可通过 media API 与播放器面板来进行。即使用`audioElement.play()`和`audioElement.pause()`来控制播放。

## 3. 构造流媒体

有了播放流程，我们还需要播放源，即二进制流。在大部分的tts api中，都会提供两种方式，一种是生成整个音频文件，一种是不断抛出合成事件，给到实时二进制音频数据。 利用第二种我们可以做到对长文本的快速启动播放，不必等到整个音频文件生成完毕。


我们假设有一个tts api (或者**任何一个能够不断提供二进制音频数据的事件**)，提供了一个`onData`事件，每次抛出一段`ArrayBuffer`的音频数据，我们可以将这个音频数据写入到`MediaSource`中，实现实时播放。

sourceBuffer用于接受音频数据：
```javascript
const sourceBuffer = this.mediaSource.addSourceBuffer('audio/webm; codecs="opus"')
sourceBuffer.appendBuffer(buffer)
```
> `addSourceBuffer`方法的参数是音频数据的MIME类型，这是一个重要的参数，所有的难点都在这里，不同的音频编码格式对应的MIME类型是不同的，需要根据具体的音频编码格式来设置。

由于`sourceBuffer.appendBuffer`函数是异步的，需要监听事件来判断是否已经添加完成，上一段buffer添加完成以后才能添加下一段。所以我们设计一个队列来控制添加顺序：

先创建一个添加buffer的promise函数：
```javascript
// 流式播放增加音频数据
function addBuffer(sourceBuffer, buffer) {
    return new Promise((resolve, reject) => {
        const handle = () => {
            sourceBuffer.removeEventListener('updateend', handle)
            resolve()
        }
        // 监听添加完成事件
        sourceBuffer.addEventListener('updateend', handle)
        // 添加音频数据
        sourceBuffer.appendBuffer(buffer)
    })
}
```
两个参数，`sourceBuffer`是上面创建的sourceBuffer，`buffer`是音频数据，他的类型是`ArrayBuffer`。

接着使用我[之前文章](https://suxuelengyin.github.io/pages/26533a/#funcitonexecqueue-%E5%87%BD%E6%95%B0%E6%89%A7%E8%A1%8C%E9%98%9F%E5%88%97)提到的函数执行队列类`FuncitonExecQueue`来控制添加顺序：
```javascript
// 创建函数执行队列
const queue = new FuncitonExecQueue()
```
调用tts api的`onData`事件时，将音频数据添加到队列中：
```javascript
ttsApi({
    onData(partBuffer) {
        // 添加音频数据到队列
        queue.add(addBuffer.bind(this, sourceBuffer, partBuffer))
    },
    onEnd() {
        // 音频数据添加完成
        queue.add(() => {
            // 结束
            mediaSource.endOfStream()
        })
    }
    
})
setTimeout(() => {
    // 开始播放
    audioElement.play()
}, 1000)
```
## 4. 启动优化

可以看到，代码中我们在ttsApi调用后，延迟1s后开始播放。这是因为需要等待网络和音频添加，事实上，这是极不安全的。一旦网络延迟超过一秒，播放可能会失败。所以我们可以在添加音频数据的时候就开始播放，这样可以保证播放。

```javascript
onData(partBuffer) {
    // 添加音频数据到队列
    queue.add(addBuffer.bind(this, sourceBuffer, partBuffer).then(()=>{
        // 添加音频数据后开始播放
        if(audioElement.paused){
            audioElement.play()
        }
    }))
    // 添加音频数据后开始播放
    audioElement.play()
}
```

这样显然存在一个问题，partBuffer的chunk size可能比较小，添加较慢，启动时音频不连续。这时候我们需要根据缓冲区的音频数据的大小以及网络情况来选取合适的播放策略。
